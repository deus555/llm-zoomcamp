{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79ad1f9-b218-47c0-9f6a-e6b44af87673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0192e6-de6e-4e90-8704-b9c076756a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x219dfef5b70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94554e8-c030-4229-9833-0ea3f983649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\User\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca271410-ff33-4fab-8613-c0228b4949dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map='cuda', torch_dtype=\"auto\" )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1401fe29-a24c-4935-9131-0c3bb50e2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "index_name = \"homework-questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c56caa0-4094-43dd-9a53-70cdab23f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "353d596b-6be3-4c4e-a75c-07d9112bc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "ANSWER: \n",
    "\"\"\".strip()\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + context_template.format(question = doc['question'], text = doc['text']) + \"\\n\\n\"\n",
    "        \n",
    "        \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49540c65-1993-4b2a-b506-b79b4d55c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = generator(prompt, max_length=500, num_return_sequences=1, truncation=True)\n",
    "    response_final = response[0]['generated_text']\n",
    "    return response_final[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cae7797-d3da-4fe7-bcf5-5da1e88e2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = es_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559d5290-77f2-4112-ac71-7216adc21f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'may I still enroll if the course has already started?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711edd45-68c7-46be-be1e-6e3f5b1e56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: may I still enroll if the course has already started?\n",
      "\n",
      "CONTEXT:\n",
      "Q: The course has already started. Can I still join it?\n",
      "A: Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\n",
      "In order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.\n",
      "\n",
      "Q: When I plotted using Matplot lib to check if median has a tail, I got the error below how can one bypass?\n",
      "A: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "\n",
      "Q: I don't know math. Can I take the course?\n",
      "A: Yes! We'll cover some linear algebra in the course, but in general, there will be very few formulas, mostly code.\n",
      "Here are some interesting videos covering linear algebra that you can already watch: ML Zoomcamp 1.8 - Linear Algebra Refresher from Alexey Grigorev or the excellent playlist from 3Blue1Brown Vectors | Chapter 1, Essence of linear algebra. Never hesitate to ask the community for help if you have any question.\n",
      "(Mélanie Fouesnard)\n",
      "\n",
      "\n",
      "\n",
      "ANSWER:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)\n",
    "#llm(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b818-2e8b-4a9e-bfc7-ac9ee069085b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
